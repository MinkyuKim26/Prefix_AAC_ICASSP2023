{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# custom\n",
    "from util import *\n",
    "from AAC_Prefix.AAC_Prefix import * # network\n",
    "from Train import *\n",
    "    \n",
    "TEST_BATCH_SIZE = 5\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available() \n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_num = 1 : Evaluation on Clotho\n",
    "# table_num = 2 : Evaluation on AudioCaps\n",
    "\n",
    "# setting_num = 1 : train dataset == test dataset\n",
    "# setting_num = 2 : train dataset != test dataset\n",
    "# setting_num = 3 : overall datasets(Clotho & AudioCaps) <- need to test by using compressed audio\n",
    "\n",
    "table_num = 2\n",
    "setting_num = 2\n",
    "\n",
    "if setting_num == 3 :\n",
    "    is_settingnum_3 = True\n",
    "else : \n",
    "    is_settingnum_3 = False\n",
    "\n",
    "model = get_model_in_table(table_num, setting_num, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader_audiocaps  = CreateDataloader(None, './AudioCaps', TEST_BATCH_SIZE, 'test', None, is_TrainDataset = False, tokenizer_type = None, is_settingnum_3 = is_settingnum_3)\n",
    "test_dataloader_clotho = CreateDataloader(None, './Clotho', TEST_BATCH_SIZE, 'evaluation', None, is_TrainDataset = False, tokenizer_type = None, is_settingnum_3 = is_settingnum_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, captions_pred, captions_gt = eval_model(model, test_dataloader_clotho, 31, 'test', True, device, 'Clotho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, captions_pred, captions_gt = eval_model(model, test_dataloader_audiocaps, 31, 'test', True, device, 'AudioCaps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
